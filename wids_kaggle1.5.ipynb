{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import FunctionTransformer,PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (ExtraTreesClassifier,RandomForestClassifier,GradientBoostingClassifier,BaggingClassifier,\n",
    "AdaBoostClassifier)\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#set seed for reproducibility\n",
    "np.random.seed(0) \n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw data\n",
    "train = pd.read_csv('training_v2.csv')\n",
    "test = pd.read_csv('unlabeled.csv.zip') #data without hopsital_death values (all nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Training Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputation for missing values for categorical variable \n",
    "cat = train.select_dtypes(include=['object']).apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "\n",
    "#Mean Encoding for categorical variables \n",
    "target = train['hospital_death']\n",
    "cat1 = pd.concat([cat,target], axis=1, sort=False)\n",
    "for header in cat1.columns:\n",
    "    if header != 'hospital_death':\n",
    "        means = cat1.groupby(header)['hospital_death'].mean()\n",
    "        cat1[header] = cat1[header].map(means)\n",
    "\n",
    "#Additive smoothing (regularization technique to avoid overfitting)\n",
    "def calc_smooth_mean(df, by, on, m):\n",
    "    # Compute the global mean\n",
    "    mean = df[on].mean()\n",
    "\n",
    "    # Compute the number of values and the mean of each group\n",
    "    agg = df.groupby(by)[on].agg(['count', 'mean'])\n",
    "    counts = agg['count']\n",
    "    means = agg['mean']\n",
    "\n",
    "    # Compute the \"smoothed\" means\n",
    "    smooth = (counts * means + m * mean) / (counts + m)\n",
    "\n",
    "    # Replace each value by the according smoothed mean\n",
    "    return df[by].map(smooth)\n",
    "\n",
    "for header in cat1.columns:\n",
    "    if header != 'hospital_death':\n",
    "        cat1[header] = calc_smooth_mean(cat1, by=header, on='hospital_death', m=10)\n",
    "\n",
    "#Imputation for missing values for numerical variable \n",
    "hosp_death = train['hospital_death']\n",
    "data_nolabel = train.drop('hospital_death', axis=1)\n",
    "num = data_nolabel.select_dtypes(include=['float64','int64'])\n",
    "num = num.fillna(num.mean())\n",
    "\n",
    "#putting back cat and num features together\n",
    "imputed_train_data = pd.concat([num,cat1], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for testing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputation for missing values for categorical variable \n",
    "cat_test = test.select_dtypes(include=['object']).apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "\n",
    "#label encoding \n",
    "le = LabelEncoder()\n",
    "for col in cat_test.columns:\n",
    "    cat_test[col] = le.fit_transform(cat_test[col])\n",
    "norm = pd.DataFrame(preprocessing.Normalizer().fit_transform(cat_test),columns=cat_test.columns)\n",
    "\n",
    "#Imputation for missing values for numerical variable \n",
    "hosp_death_test = test['hospital_death']\n",
    "data_nolabel_test = test.drop('hospital_death', axis=1)\n",
    "num_test = data_nolabel_test.select_dtypes(include=['float64','int64'])\n",
    "num_test = num_test.fillna(num_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting back cat and num features together\n",
    "imputed_test = pd.concat([num_test,norm], axis=1, sort=False)\n",
    "x_testing = imputed_test.drop(['encounter_id', 'patient_id', 'hospital_id'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = imputed_train_data.sample(frac=1).reset_index(drop=True) #shuffle the data\n",
    "x_training = final_data.drop(['encounter_id', 'patient_id', 'hospital_id','hospital_death'], axis=1).copy()\n",
    "y_training = final_data['hospital_death']\n",
    "\n",
    "#Over Sampling to solve output class imbalance problem\n",
    "# sm = SMOTE(random_state=random_state)\n",
    "# X_training, y_trainings = sm.fit_sample(x_training,y_training)\n",
    "\n",
    "# X_train = x_training.copy()\n",
    "# y_train = y_training.copy()\n",
    "# X_test = x_testing.copy()\n",
    "\n",
    "#Data Partition\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_training, y_training,test_size = 0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 771 ms, total: 1min 11s\n",
      "Wall time: 59.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>93.239928</td>\n",
       "      <td>0.901132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>93.103636</td>\n",
       "      <td>0.895888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classifier   Accuracy       AUC\n",
       "0  LGBMClassifier  93.239928  0.901132\n",
       "0   XGBClassifier  93.103636  0.895888"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "classifiers = [LGBMClassifier(), \n",
    "               XGBClassifier()]\n",
    "log_cols=[\"Classifier\", \"Accuracy\",\"AUC\"]\n",
    "result = pd.DataFrame(columns=log_cols)\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    prob = clf.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, prob)\n",
    "    log_entry = pd.DataFrame([[name, acc*100, auc]],columns=log_cols)\n",
    "    result = result.append(log_entry)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LGBMClassifier()]\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    prob = clf.predict_proba(X_test)[:,1]\n",
    "encounter_id = pd.DataFrame(test['encounter_id'])\n",
    "prob1 = pd.DataFrame(prob).rename(columns = {0: 'hospital_death'})\n",
    "output = pd.concat([encounter_id,prob1], axis=1, sort=False)\n",
    "output.to_csv('DSDJ1.5.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cross validation\n",
    "models = []\n",
    "models.append(('LGBMC', LGBMClassifier()))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=random_state)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    (msg)\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.65, 'learning_rate': 0.005, 'n_estimators': 40, 'num_leaves': 6, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n",
      "0.9136981671963669\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'objective': 'binary',\n",
    "          'nthread': 3, # Updated from nthread\n",
    "          'num_leaves': 64,\n",
    "          'learning_rate': 0.05,\n",
    "          'max_bin': 512,\n",
    "          'subsample_for_bin': 200,\n",
    "          'subsample': 1,\n",
    "          'subsample_freq': 1,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'reg_alpha': 5,\n",
    "          'reg_lambda': 10,\n",
    "          'min_split_gain': 0.5,\n",
    "          'min_child_weight': 1,\n",
    "          'min_child_samples': 5,\n",
    "          'scale_pos_weight': 1,\n",
    "          'num_class' : 1,\n",
    "          'metric' : 'binary_error'} \n",
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005],\n",
    "    'n_estimators': [40],\n",
    "    'num_leaves': [6,8,12,16],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'random_state' : [501],\n",
    "    'colsample_bytree' : [0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "mdl = LGBMClassifier(boosting_type= 'gbdt',\n",
    "          objective = 'binary',\n",
    "          n_jobs = 3,\n",
    "          silent = True,\n",
    "          max_depth = params['max_depth'],\n",
    "          max_bin = params['max_bin'],\n",
    "          subsample_for_bin = params['subsample_for_bin'],\n",
    "          subsample = params['subsample'],\n",
    "          subsample_freq = params['subsample_freq'],\n",
    "          min_split_gain = params['min_split_gain'],\n",
    "          min_child_weight = params['min_child_weight'],\n",
    "          min_child_samples = params['min_child_samples'],\n",
    "          scale_pos_weight = params['scale_pos_weight'])\n",
    "# To view the default model params:\n",
    "mdl.get_params().keys()\n",
    "\n",
    "# Create the grid\n",
    "grid = GridSearchCV(mdl, gridParams,\n",
    "                    verbose=0,\n",
    "                    cv=4,\n",
    "                    n_jobs=2)\n",
    "# Run the grid\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model after tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "classifiers = [LGBMClassifier(boosting_type='gbdt',\n",
    "                              colsample_bytree=0.65, \n",
    "                              learning_rate=0.005, \n",
    "                              n_estimators = 40,\n",
    "                              num_leaves=6, \n",
    "                              objective='binary', \n",
    "                              random_state=501, \n",
    "                              reg_alpha=1, \n",
    "                              reg_lambda=1, \n",
    "                              subsample=0.7), \n",
    "               XGBClassifier()]\n",
    "log_cols=[\"Classifier\", \"Accuracy\",\"AUC\"]\n",
    "result = pd.DataFrame(columns=log_cols)\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    prob = clf.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, prob)\n",
    "    log_entry = pd.DataFrame([[name, acc*100, auc]],columns=log_cols)\n",
    "    result = result.append(log_entry)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
